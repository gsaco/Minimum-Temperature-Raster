{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§Š Peru Minimum Temperature (Tmin) Raster Analysis\n",
    "\n",
    "This notebook performs comprehensive analysis of Peru's minimum temperature data including:\n",
    "- Zonal statistics extraction by administrative units\n",
    "- Climate risk analysis (frost/cold surges)\n",
    "- Visualization of temperature patterns\n",
    "- Data preparation for Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterstats import zonal_stats\n",
    "import rioxarray as rxr\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "base_path = Path('.').parent\n",
    "data_path = base_path / 'data'\n",
    "raster_path = base_path / 'tmin_raster.tif'\n",
    "\n",
    "print(f\"Base path: {base_path}\")\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Raster path: {raster_path}\")\n",
    "print(f\"Raster exists: {raster_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Raster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raster with rasterio\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data = src.read()\n",
    "    raster_meta = src.meta\n",
    "    raster_crs = src.crs\n",
    "    raster_bounds = src.bounds\n",
    "    raster_transform = src.transform\n",
    "\n",
    "print(f\"Raster shape: {raster_data.shape}\")\n",
    "print(f\"Raster CRS: {raster_crs}\")\n",
    "print(f\"Raster bounds: {raster_bounds}\")\n",
    "print(f\"Number of bands: {raster_data.shape[0]}\")\n",
    "print(f\"Data type: {raster_data.dtype}\")\n",
    "print(f\"No data value: {raster_meta.get('nodata')}\")\n",
    "\n",
    "# Basic statistics\n",
    "for band in range(raster_data.shape[0]):\n",
    "    band_data = raster_data[band]\n",
    "    valid_data = band_data[band_data != raster_meta.get('nodata', np.nan)]\n",
    "    print(f\"\\nBand {band + 1} statistics:\")\n",
    "    print(f\"  Min: {np.nanmin(valid_data):.2f}\")\n",
    "    print(f\"  Max: {np.nanmax(valid_data):.2f}\")\n",
    "    print(f\"  Mean: {np.nanmean(valid_data):.2f}\")\n",
    "    print(f\"  Valid pixels: {len(valid_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raster\n",
    "fig, axes = plt.subplots(1, min(3, raster_data.shape[0]), figsize=(15, 5))\n",
    "if raster_data.shape[0] == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, ax in enumerate(axes[:raster_data.shape[0]]):\n",
    "    band_data = raster_data[i]\n",
    "    im = ax.imshow(band_data, cmap='coolwarm', vmin=np.nanpercentile(band_data, 1), \n",
    "                   vmax=np.nanpercentile(band_data, 99))\n",
    "    ax.set_title(f'Band {i+1} - Minimum Temperature')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    plt.colorbar(im, ax=ax, label='Temperature (Â°C)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Load Administrative Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the download script\n",
    "import sys\n",
    "sys.path.append(str(data_path))\n",
    "\n",
    "try:\n",
    "    from download_boundaries import download_peru_boundaries\n",
    "    download_peru_boundaries()\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading boundaries: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load administrative boundaries\n",
    "boundaries_files = {\n",
    "    'departments': data_path / 'peru_departments.geojson',\n",
    "    'districts': data_path / 'peru_districts.geojson'\n",
    "}\n",
    "\n",
    "boundaries = {}\n",
    "for level, file_path in boundaries_files.items():\n",
    "    if file_path.exists():\n",
    "        gdf = gpd.read_file(file_path)\n",
    "        # Ensure CRS is EPSG:4326\n",
    "        if gdf.crs != 'EPSG:4326':\n",
    "            gdf = gdf.to_crs('EPSG:4326')\n",
    "        boundaries[level] = gdf\n",
    "        print(f\"Loaded {level}: {len(gdf)} features\")\n",
    "        print(f\"  Columns: {gdf.columns.tolist()}\")\n",
    "\n",
    "# Use the most detailed level available\n",
    "if 'districts' in boundaries:\n",
    "    admin_gdf = boundaries['districts'].copy()\n",
    "    admin_level = 'districts'\n",
    "else:\n",
    "    admin_gdf = boundaries['departments'].copy()\n",
    "    admin_level = 'departments'\n",
    "\n",
    "print(f\"\\nUsing {admin_level} for analysis: {len(admin_gdf)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize boundaries\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 12))\n",
    "admin_gdf.plot(ax=ax, facecolor='lightblue', edgecolor='black', alpha=0.7)\n",
    "ax.set_title(f'Peru Administrative Boundaries ({admin_level.title()})')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Zonal Statistics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zonal_stats(raster_path, geometries, band=1):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive zonal statistics.\n",
    "    Returns statistics for each geometry.\n",
    "    \"\"\"\n",
    "    stats_list = []\n",
    "    \n",
    "    # Define statistics to calculate\n",
    "    stats_funcs = [\n",
    "        'count', 'min', 'max', 'mean', 'std',\n",
    "        'percentile_10', 'percentile_90', 'percentile_25', 'percentile_75'\n",
    "    ]\n",
    "    \n",
    "    print(f\"Calculating zonal statistics for band {band}...\")\n",
    "    \n",
    "    # Calculate zonal stats\n",
    "    zonal_results = zonal_stats(\n",
    "        geometries,\n",
    "        str(raster_path),\n",
    "        band=band,\n",
    "        stats=stats_funcs,\n",
    "        nodata=raster_meta.get('nodata')\n",
    "    )\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    stats_df = pd.DataFrame(zonal_results)\n",
    "    \n",
    "    # Add custom metrics\n",
    "    stats_df['range'] = stats_df['max'] - stats_df['min']  # Temperature range\n",
    "    stats_df['frost_risk'] = (stats_df['min'] < 0).astype(int)  # Binary frost risk\n",
    "    stats_df['extreme_cold'] = (stats_df['percentile_10'] < -5).astype(int)  # Extreme cold risk\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "# Calculate zonal statistics for the first band\n",
    "zonal_stats_df = calculate_zonal_stats(raster_path, admin_gdf.geometry, band=1)\n",
    "\n",
    "# Combine with administrative data\n",
    "admin_stats = admin_gdf.copy()\n",
    "admin_stats = pd.concat([admin_stats.reset_index(drop=True), zonal_stats_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(f\"Zonal statistics calculated for {len(admin_stats)} administrative units\")\n",
    "print(f\"Statistics columns: {zonal_stats_df.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "admin_stats[['NAME_CLEAN', 'mean', 'min', 'max', 'std', 'frost_risk']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for units and rescale if necessary\n",
    "# If temperatures seem to be scaled (e.g., Â°C * 10), rescale them\n",
    "temp_cols = ['min', 'max', 'mean', 'std', 'percentile_10', 'percentile_90', 'percentile_25', 'percentile_75', 'range']\n",
    "\n",
    "print(\"Temperature statistics summary:\")\n",
    "print(admin_stats[temp_cols].describe())\n",
    "\n",
    "# Check if values seem to be scaled (typical range for Peru should be around -10 to 30Â°C)\n",
    "mean_temp_range = admin_stats['mean'].max() - admin_stats['mean'].min()\n",
    "if mean_temp_range > 100:  # Likely scaled by 10 or 100\n",
    "    print(\"\\nTemperature values appear to be scaled. Rescaling...\")\n",
    "    scale_factor = 10 if mean_temp_range < 1000 else 100\n",
    "    for col in temp_cols:\n",
    "        admin_stats[col] = admin_stats[col] / scale_factor\n",
    "    \n",
    "    # Recalculate frost risk with corrected values\n",
    "    admin_stats['frost_risk'] = (admin_stats['min'] < 0).astype(int)\n",
    "    admin_stats['extreme_cold'] = (admin_stats['percentile_10'] < -5).astype(int)\n",
    "    \n",
    "    print(f\"Rescaled by factor of {scale_factor}\")\n",
    "    print(\"Updated temperature statistics:\")\n",
    "    print(admin_stats[temp_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Distribution of mean minimum temperatures\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram\n",
    "admin_stats['mean'].hist(bins=30, ax=ax1, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax1.set_xlabel('Mean Minimum Temperature (Â°C)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Mean Minimum Temperatures')\n",
    "ax1.axvline(admin_stats['mean'].mean(), color='red', linestyle='--', label=f'Mean: {admin_stats[\"mean\"].mean():.2f}Â°C')\n",
    "ax1.legend()\n",
    "\n",
    "# Box plot\n",
    "admin_stats.boxplot(column=['mean', 'min', 'max'], ax=ax2)\n",
    "ax2.set_ylabel('Temperature (Â°C)')\n",
    "ax2.set_title('Temperature Statistics Distribution')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Ranking - Coldest and Warmest areas\n",
    "n_top = min(15, len(admin_stats))\n",
    "\n",
    "# Sort by mean temperature\n",
    "coldest = admin_stats.nsmallest(n_top, 'mean')\n",
    "warmest = admin_stats.nlargest(n_top, 'mean')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Coldest areas (highest frost risk)\n",
    "coldest_plot = coldest.plot(x='NAME_CLEAN', y='mean', kind='barh', ax=ax1, color='lightblue')\n",
    "ax1.set_title(f'Top {n_top} Coldest Areas (Highest Frost Risk)')\n",
    "ax1.set_xlabel('Mean Minimum Temperature (Â°C)')\n",
    "ax1.set_ylabel('')\n",
    "\n",
    "# Warmest areas (lowest frost risk)\n",
    "warmest_plot = warmest.plot(x='NAME_CLEAN', y='mean', kind='barh', ax=ax2, color='lightcoral')\n",
    "ax2.set_title(f'Top {n_top} Warmest Areas (Lowest Frost Risk)')\n",
    "ax2.set_xlabel('Mean Minimum Temperature (Â°C)')\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"COLDEST AREAS (Highest Climate Risk):\")\n",
    "print(coldest[['NAME_CLEAN', 'mean', 'min', 'frost_risk']].to_string())\n",
    "print(\"\\nWARMEST AREAS (Lowest Climate Risk):\")\n",
    "print(warmest[['NAME_CLEAN', 'mean', 'min', 'frost_risk']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Static Choropleth Map\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 14))\n",
    "\n",
    "# Create choropleth map\n",
    "admin_stats.plot(\n",
    "    column='mean',\n",
    "    cmap='RdYlBu_r',\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.5,\n",
    "    legend_kwds={'label': 'Mean Minimum Temperature (Â°C)',\n",
    "                'orientation': 'horizontal',\n",
    "                'shrink': 0.8}\n",
    ")\n",
    "\n",
    "ax.set_title('Peru: Mean Minimum Temperature by Administrative Unit', fontsize=16, pad=20)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Remove axes ticks for cleaner look\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(data_path / 'peru_tmin_map.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Climate Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate risk classification\n",
    "admin_stats['risk_level'] = 'Low'\n",
    "admin_stats.loc[admin_stats['mean'] < 5, 'risk_level'] = 'Medium'\n",
    "admin_stats.loc[admin_stats['mean'] < 0, 'risk_level'] = 'High'\n",
    "admin_stats.loc[admin_stats['min'] < -10, 'risk_level'] = 'Very High'\n",
    "\n",
    "# Summary statistics by risk level\n",
    "risk_summary = admin_stats.groupby('risk_level').agg({\n",
    "    'NAME_CLEAN': 'count',\n",
    "    'mean': ['mean', 'min', 'max'],\n",
    "    'min': ['mean', 'min'],\n",
    "    'frost_risk': 'sum',\n",
    "    'extreme_cold': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "print(\"CLIMATE RISK ANALYSIS SUMMARY:\")\n",
    "print(risk_summary)\n",
    "\n",
    "# Visualize risk distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Risk level distribution\n",
    "risk_counts = admin_stats['risk_level'].value_counts()\n",
    "risk_counts.plot(kind='pie', ax=ax1, autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Distribution of Climate Risk Levels')\n",
    "ax1.set_ylabel('')\n",
    "\n",
    "# Temperature vs Risk\n",
    "risk_colors = {'Low': 'green', 'Medium': 'yellow', 'High': 'orange', 'Very High': 'red'}\n",
    "for risk in admin_stats['risk_level'].unique():\n",
    "    data = admin_stats[admin_stats['risk_level'] == risk]\n",
    "    ax2.scatter(data['mean'], data['min'], label=risk, alpha=0.7, color=risk_colors.get(risk, 'blue'))\n",
    "\n",
    "ax2.set_xlabel('Mean Minimum Temperature (Â°C)')\n",
    "ax2.set_ylabel('Absolute Minimum Temperature (Â°C)')\n",
    "ax2.set_title('Temperature Distribution by Risk Level')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results for Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for Streamlit app\n",
    "output_data = admin_stats.copy()\n",
    "\n",
    "# Select relevant columns for the app\n",
    "app_columns = [\n",
    "    'NAME_CLEAN', 'geometry', \n",
    "    'count', 'min', 'max', 'mean', 'std',\n",
    "    'percentile_10', 'percentile_90', 'percentile_25', 'percentile_75',\n",
    "    'range', 'frost_risk', 'extreme_cold', 'risk_level'\n",
    "]\n",
    "\n",
    "# Add department/region info if available\n",
    "if 'DEPT_CLEAN' in output_data.columns:\n",
    "    app_columns.insert(1, 'DEPT_CLEAN')\n",
    "elif any(col for col in output_data.columns if 'admin' in col.lower() or 'region' in col.lower()):\n",
    "    region_col = [col for col in output_data.columns if 'admin' in col.lower() or 'region' in col.lower()][0]\n",
    "    app_columns.insert(1, region_col)\n",
    "\n",
    "# Filter columns that exist\n",
    "existing_columns = [col for col in app_columns if col in output_data.columns]\n",
    "output_data = output_data[existing_columns]\n",
    "\n",
    "# Save as GeoJSON for Streamlit\n",
    "output_data.to_file(data_path / 'peru_tmin_analysis.geojson', driver='GeoJSON')\n",
    "\n",
    "# Save as CSV (without geometry) for easy download\n",
    "csv_data = output_data.drop(columns=['geometry']).copy()\n",
    "csv_data.to_csv(data_path / 'peru_tmin_analysis.csv', index=False)\n",
    "\n",
    "print(f\"Saved analysis results:\")\n",
    "print(f\"  - GeoJSON: {data_path / 'peru_tmin_analysis.geojson'}\")\n",
    "print(f\"  - CSV: {data_path / 'peru_tmin_analysis.csv'}\")\n",
    "print(f\"  - Map: {data_path / 'peru_tmin_map.png'}\")\n",
    "print(f\"\\nData shape: {output_data.shape}\")\n",
    "print(f\"Columns: {output_data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PERU MINIMUM TEMPERATURE ANALYSIS - KEY FINDINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸ“Š DATASET OVERVIEW:\")\n",
    "print(f\"  â€¢ Administrative units analyzed: {len(admin_stats)}\")\n",
    "print(f\"  â€¢ Administrative level: {admin_level}\")\n",
    "print(f\"  â€¢ Raster bands processed: {raster_data.shape[0]}\")\n",
    "\n",
    "print(f\"\\nðŸŒ¡ï¸ TEMPERATURE STATISTICS:\")\n",
    "print(f\"  â€¢ Overall mean minimum temperature: {admin_stats['mean'].mean():.2f}Â°C\")\n",
    "print(f\"  â€¢ Coldest area mean: {admin_stats['mean'].min():.2f}Â°C\")\n",
    "print(f\"  â€¢ Warmest area mean: {admin_stats['mean'].max():.2f}Â°C\")\n",
    "print(f\"  â€¢ Temperature range: {admin_stats['mean'].max() - admin_stats['mean'].min():.2f}Â°C\")\n",
    "\n",
    "print(f\"\\nâ„ï¸ FROST RISK ANALYSIS:\")\n",
    "print(f\"  â€¢ Areas with frost risk (min < 0Â°C): {admin_stats['frost_risk'].sum()} ({admin_stats['frost_risk'].mean()*100:.1f}%)\")\n",
    "print(f\"  â€¢ Areas with extreme cold risk (p10 < -5Â°C): {admin_stats['extreme_cold'].sum()} ({admin_stats['extreme_cold'].mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ HIGH-RISK AREAS (Top 5 coldest):\")\n",
    "high_risk = admin_stats.nsmallest(5, 'mean')\n",
    "for idx, row in high_risk.iterrows():\n",
    "    print(f\"  â€¢ {row['NAME_CLEAN']}: {row['mean']:.2f}Â°C (min: {row['min']:.2f}Â°C)\")\n",
    "\n",
    "print(f\"\\nðŸ”¥ PRIORITY REGIONS FOR POLICY INTERVENTION:\")\n",
    "priority_areas = admin_stats[admin_stats['risk_level'].isin(['High', 'Very High'])]\n",
    "print(f\"  â€¢ {len(priority_areas)} areas require immediate attention\")\n",
    "print(f\"  â€¢ Focus regions: High-Andean areas and Amazon cold surge zones\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}